{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Flatten, Dense, GlobalAveragePooling2D,Dropout,Conv2D\n",
    "from keras.applications.densenet import DenseNet169, DenseNet121, DenseNet201\n",
    "from keras.applications.nasnet import NASNetLarge\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import roc_auc_score, cohen_kappa_score\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from keras.applications.mobilenetv2 import MobileNetV2\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "import pydicom\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.utils import Sequence\n",
    "from keras import backend as keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import math\n",
    "from keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, Dropout, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers \n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X,y, batch_size=8):\n",
    "    '''\n",
    "    Return a random image from X, y\n",
    "    '''\n",
    "    \n",
    "    while True:\n",
    "        # choose batch_size random images / labels from the data\n",
    "        #idx = np.random.randint(0, X.shape[0], batch_size)\n",
    "        i=0\n",
    "        for idx in np.arange(8,X.shape[0], batch_size):\n",
    "        \n",
    "            im = np.array(X[i:idx])\n",
    "            label = np.array(y[i:idx])\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            yield im,label\n",
    "            i = idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "class Metrics(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "     self.val_f1s = []\n",
    "     self.val_recalls = []\n",
    "     self.val_precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "     val_predict = (np.asarray(self.model.predict(X_test_feats))).round()\n",
    "     val_targ = Y_test\n",
    "#      print(val_targ.shape)   \n",
    "#      print(val_targ)\n",
    "#      print(val_predict.shape)   \n",
    "#      print(val_predict)   \n",
    "     targ = []\n",
    "     pred = []\n",
    "     for x in val_targ:\n",
    "        targ.append(np.argmax(x))\n",
    "     for x in val_predict:\n",
    "        pred.append(np.argmax(x))\n",
    "#      print(targ)\n",
    "#      print(pred)\n",
    "        \n",
    "     _val_f1 = f1_score(targ, pred)\n",
    "     \n",
    "     _val_recall = recall_score(targ, pred)\n",
    "     _val_precision = precision_score(targ, pred)\n",
    "     self.val_f1s.append(_val_f1)\n",
    "     self.val_recalls.append(_val_recall)\n",
    "     self.val_precisions.append(_val_precision)\n",
    "     print(\"— val_f1: {0} — val_precision: {1} — val_recall {2} \".format(_val_f1, _val_precision, _val_recall))\n",
    "     return\n",
    "\n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "class roc_callback(Callback):\n",
    "    def __init__(self,validation_data):\n",
    "#         self.x = training_data[0]\n",
    "#         self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "#         y_pred = self.model.predict(self.x)\n",
    "#         roc = roc_auc_score(self.y, y_pred)\n",
    "        if(epoch%1==0):\n",
    "            print(\"Calc Roc\")\n",
    "            all_rocs = []\n",
    "            y_pred_val = self.model.predict(pad_X_test,verbose=1)\n",
    "            for d in range(15):\n",
    "                try:\n",
    "                    roc_val = roc_auc_score(pad_Y_test[:,d], y_pred_val[:,d])\n",
    "                    all_rocs.append(roc_val)\n",
    "                except:\n",
    "                    pass\n",
    "            all_rocs = np.array(all_rocs)\n",
    "            mean_roc = np.mean(all_rocs)\n",
    "            \n",
    "            f1s = {}\n",
    "            for d in range(15):\n",
    "                try:\n",
    "                    score = f1_score(pad_Y_test[:,d], np.around(y_pred_val[:,d]))\n",
    "                    f1s[global_cls[d]] = score\n",
    "                except:\n",
    "                    print(global_cls[d])\n",
    "            avg_f1 = np.average(list(f1s.values()))\n",
    "            \n",
    "            print(\"ROC VAL {0}\".format(mean_roc))\n",
    "            print(\"AVG F1 {0}\".format(avg_f1))\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_net(input_shape, dropout_rate, l2_lambda):\n",
    " \n",
    "    # Encoder\n",
    "    input = Input(shape = input_shape, name = \"input\")\n",
    "    conv1_1 = Conv2D(32, (3, 3), padding = \"same\", activation='relu', kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv1_1\")(input)\n",
    "    conv1_1 = bn(name = \"conv1_1_bn\")(conv1_1)\n",
    "    conv1_2 = Conv2D(32, (3, 3), padding = \"same\", activation='relu', kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv1_2\")(conv1_1)\n",
    "    conv1_2 = bn(name = \"conv1_2_bn\")(conv1_2)\n",
    "    pool1 = MaxPooling2D(name = \"pool1\")(conv1_2)\n",
    "    drop1 = Dropout(dropout_rate)(pool1)\n",
    "\n",
    "    conv2_1 = Conv2D(64, (3, 3), padding = \"same\", activation='relu', kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv2_1\")(pool1)\n",
    "    conv2_1 = bn(name = \"conv2_1_bn\")(conv2_1)\n",
    "    conv2_2 = Conv2D(64, (3, 3), padding = \"same\", activation='relu', kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv2_2\")(conv2_1)\n",
    "    conv2_2 = bn(name = \"conv2_2_bn\")(conv2_2)\n",
    "    pool2 = MaxPooling2D(name = \"pool2\")(conv2_2)\n",
    "    drop2 = Dropout(dropout_rate)(pool2)\n",
    "\n",
    "    conv3_1 = Conv2D(128, (3, 3), padding = \"same\", activation='relu', kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv3_1\")(pool2)\n",
    "    conv3_1 = bn(name = \"conv3_1_bn\")(conv3_1)\n",
    "    conv3_2 = Conv2D(128, (3, 3), padding = \"same\", activation='relu', kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv3_2\")(conv3_1)\n",
    "    conv3_2 = bn(name = \"conv3_2_bn\")(conv3_2)\n",
    "    pool3 = MaxPooling2D(name = \"pool3\")(conv3_2)\n",
    "    drop3 = Dropout(dropout_rate)(pool3)  \n",
    "\n",
    "    conv4_1 = Conv2D(256, (3, 3), padding = \"same\", activation='relu', kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv4_1\")(pool3)\n",
    "    conv4_1 = bn(name = \"conv4_1_bn\")(conv4_1)\n",
    "    conv4_2 = Conv2D(256, (3, 3), padding = \"same\", activation='relu', kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv4_2\")(conv4_1)\n",
    "    conv4_2 = bn(name = \"conv4_2_bn\")(conv4_2)\n",
    "    pool4 = MaxPooling2D(name = \"pool4\")(conv4_2)\n",
    "    drop4 = Dropout(dropout_rate)(pool4)  \n",
    "\n",
    "    conv5_1 = Conv2D(512, (3, 3), padding = \"same\", activation='relu', kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv5_1\")(pool4)\n",
    "    conv5_1 = bn(name = \"conv5_1_bn\")(conv5_1)\n",
    "    conv5_2 = Conv2D(512, (3, 3), padding = \"same\", activation='relu', kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv5_2\")(conv5_1)\n",
    "    conv5_2 = bn(name = \"conv5_2_bn\")(conv5_2)\n",
    "\n",
    "    # Decoder\n",
    "    upconv6 = Conv2DTranspose(256,(2, 2), strides=(2, 2), padding='same')(conv5_2)\n",
    "    upconv6 = Dropout(dropout_rate)(upconv6)\n",
    "    concat6 = concatenate([conv4_2, upconv6], name = \"concat6\")\n",
    "    conv6_1 = Conv2D(256, (3, 3), padding = \"same\", kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv6_1\")(concat6)\n",
    "    conv6_1 = bn(name = \"conv6_1_bn\")(conv6_1)\n",
    "    conv6_2 = Conv2D(256, (3, 3), padding = \"same\", kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv6_2\")(conv6_1)\n",
    "    conv6_2 = bn(name = \"conv6_2_bn\")(conv6_2)\n",
    "\n",
    "    upconv7 = Conv2DTranspose(128,(2, 2), strides=(2, 2), padding='same')(conv6_2)\n",
    "    upconv7 = Dropout(dropout_rate)(upconv7)\n",
    "    concat7 = concatenate([conv3_2, upconv7], name = \"concat7\")\n",
    "    conv7_1 = Conv2D(128, (3, 3), padding = \"same\", kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv7_1\")(concat7)\n",
    "    conv7_1 = bn(name = \"conv7_1_bn\")(conv7_1)\n",
    "    conv7_2 = Conv2D(128, (3, 3), padding = \"same\", kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv7_2\")(conv7_1)\n",
    "    conv7_2 = bn(name = \"conv7_2_bn\")(conv7_2)\n",
    "\n",
    "    upconv8 = Conv2DTranspose(64,(2, 2), strides=(2, 2), padding='same')(conv7_2)\n",
    "    upconv8 = Dropout(dropout_rate)(upconv8)\n",
    "    concat8 = concatenate([conv2_2, upconv8], name = \"concat8\")\n",
    "    conv8_1 = Conv2D(64, (3, 3), padding = \"same\", kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv8_1\")(concat8)\n",
    "    conv8_1 = bn(name = \"conv8_1_bn\")(conv8_1)\n",
    "    conv8_2 = Conv2D(64, (3, 3), padding = \"same\", kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv8_2\")(conv8_1)\n",
    "    conv8_2 = bn(name = \"conv8_2_bn\")(conv8_2)\n",
    "\n",
    "    upconv9 = Conv2DTranspose(32,(2, 2), strides=(2, 2), padding='same')(conv8_2)\n",
    "    upconv9 = Dropout(dropout_rate)(upconv9)\n",
    "    concat9 = concatenate([conv1_2, upconv9], name = \"concat9\")\n",
    "    conv9_1 = Conv2D(32, (3, 3), padding = \"same\", kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv9_1\")(concat9)\n",
    "    conv9_1 = bn(name = \"conv9_1_bn\")(conv9_1)\n",
    "    conv9_2 = Conv2D(32, (3, 3), padding = \"same\", kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv9_2\")(conv9_1)\n",
    "    conv9_2 = bn(name = \"conv9_2_bn\")(conv9_2)\n",
    "    dropout = Dropout(dropout_rate)(conv9_2)\n",
    "   \n",
    "    up6 = UpSampling2D(size=(8,8))(concat6)\n",
    "    up7 = UpSampling2D(size=(4,4))(concat7)\n",
    "    up8 = UpSampling2D(size=(2,2))(concat8)\n",
    "    concate1 = concatenate([up6,up7,up8,dropout])\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), padding = \"same\", activation = 'sigmoid', name = \"conv10\")(concate1)\n",
    "\n",
    "\n",
    "    model = Model(input, conv10)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(pretrained_weights = None,input_size = (256,256,3)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input = inputs, output = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    #model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "    \tmodel.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load('../Numpy_Data/X_train_255.npy', mmap_mode='r+')\n",
    "y=np.load('../Numpy_Data/Y_train_255.npy', mmap_mode='r+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_new=[]\n",
    "for a in y1:\n",
    "    y_new.append(cv2.cvtColor(a, cv2.COLOR_RGB2GRAY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y=np.array(y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y=y/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y=np.reshape(y, (10675, 256,256,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x=[]\n",
    "Y=[]\n",
    "for i in range(0, len(X)):\n",
    "    x.append(cv2.resize(X[i], (128,128)))\n",
    "    Y.append(cv2.resize(y[i], (128,128)))\n",
    "\n",
    "x=np.array(x)\n",
    "Y=np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X[:8500]\n",
    "X_valid=X[8500:]\n",
    "Y_train=y[:8500]\n",
    "Y_valid=y[8500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X\n",
    "del y\n",
    "del x\n",
    "del Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(true, preds):  \n",
    "    scores  = []\n",
    "    for i in range(len(true)):\n",
    "        im1 = true[i]\n",
    "        im2 = np.around(preds[i])\n",
    "        intersection = np.logical_and(im1, im2)\n",
    "        score = 2. * intersection.sum() / (im1.sum() + im2.sum())\n",
    "        scores.append(score)\n",
    "    return np.array(scores).mean()#, scores\n",
    "\n",
    "def dice_score(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f)+K.epsilon())\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dice_call(Callback):\n",
    "    def __init__(self,validation_data):\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        if(epoch%1==0):\n",
    "            print(\"Calc DICE\")\n",
    "            y_pred_val = np.around(self.model.predict(self.x_val,verbose=1))\n",
    "            try:\n",
    "                dice_val = dice(self.y_val, y_pred_val)\n",
    "            except:\n",
    "                pass\n",
    "            print(\"DICE VAL {0}\".format(dice_val))\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1.0\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f1 = K.flatten(K.round(y_pred))\n",
    "    intersection = K.sum(y_true_f * y_pred_f1)\n",
    "    return  (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f1) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [256, 256, 3]\n",
    "dropout_rate = 0.3\n",
    "l2_lambda = 0.0002\n",
    "\n",
    "#model = unet(None, input_shape)\n",
    "model = u_net(input_shape, dropout_rate, l2_lambda)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = [dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_call1 = dice_call(validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('./Unet_updated_npy.hdf5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(batch_generator(X_train, Y_train), validation_data=(X_valid, Y_valid), epochs=100, steps_per_epoch=len(X_train)/32, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./Unet_updated_npy.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.load('../Numpy_Data/X_test.npy', mmap_mode='r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test, verbose=1, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=y_pred[1]\n",
    "image=np.reshape(image, (256,256))\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv=pd.read_csv('../SIIM_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2rle(img, width, height):\n",
    "    rle = []\n",
    "    lastColor = 0;\n",
    "    currentPixel = 0;\n",
    "    runStart = -1;\n",
    "    runLength = 0;\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            currentColor = img[x][y]\n",
    "            if currentColor != lastColor:\n",
    "                if currentColor == 255:\n",
    "                    runStart = currentPixel;\n",
    "                    runLength = 1;\n",
    "                else:\n",
    "                    rle.append(str(runStart));\n",
    "                    rle.append(str(runLength));\n",
    "                    runStart = -1;\n",
    "                    runLength = 0;\n",
    "                    currentPixel = 0;\n",
    "            elif runStart > -1:\n",
    "                runLength += 1\n",
    "            lastColor = currentColor;\n",
    "            currentPixel+=1;\n",
    "\n",
    "    return \" \".join(rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle2mask(rle, width, height):\n",
    "    mask= np.zeros(width* height)\n",
    "    array = np.asarray([int(x) for x in rle.split()])\n",
    "    starts = array[0::2]\n",
    "    lengths = array[1::2]\n",
    "\n",
    "    current_position = 0\n",
    "    for index, start in enumerate(starts):\n",
    "        current_position += start\n",
    "        mask[current_position:current_position+lengths[index]] = 255\n",
    "        current_position += lengths[index]\n",
    "\n",
    "    return mask.reshape(width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv=test_csv.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_new=rle2mask(image_encoded[test_csv['0'][1]],256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(y_pred[0], (256,256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask_new, 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_encoded={}\n",
    "for index, image in enumerate(y_pred):\n",
    "    if np.max(image)==0:\n",
    "        image_encoded[test_csv['0'][index]]=-1\n",
    "        \n",
    "    else:\n",
    "        image=np.reshape(image, (256,256))\n",
    "        image_encoded[test_csv['0'][index]]=mask2rle(image, 256, 256)\n",
    "    print (index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame.from_dict(image_encoded, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_images=[]\n",
    "for i in test_csv['0']:\n",
    "    a=i.split('/')[-1]\n",
    "    a=a.split('.png')\n",
    "    list_of_images.append(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (image_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['ImageId']=list_of_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['EncodedPixels']=image_encoded.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('./submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1=y_pred_1.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=150\n",
    "plt.imshow(np.around(y_pred[i]), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Y_valid[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.around(y_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(16,16))\n",
    "columns = 4\n",
    "rows = 5\n",
    "j=0\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = np.random.randint(1,2000)\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(np.around(y[img]), cmap='gray')\n",
    "    j=j+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(16,16))\n",
    "columns = 4\n",
    "rows = 5\n",
    "j=0\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = np.random.randint(1,2000)\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(Y_train[j], cmap='gray')\n",
    "    j=j+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
